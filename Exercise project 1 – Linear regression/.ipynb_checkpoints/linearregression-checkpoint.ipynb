{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# usual imports\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# pip install scikit-learn\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# usual imports\n",
    "# pip install scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# https://www.kaggle.com/datasets/mirichoi0218/insurance/data\n",
    "csv_path = \"insurance.csv\"\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Looks Okay with 1338 Entries with non null values.\n",
    "- Age, Childrens, BMI & charges are Numerical.\n",
    "- Sex, Smoker & Region looks like Categorical Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking summary of numerical values\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking distributtions of the datas.\n",
    "df.hist(bins=50, figsize=(20,15))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Categorical Data's\n",
    "print(df['sex'].value_counts())\n",
    "print(df['smoker'].value_counts())\n",
    "print(df['region'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Dictionary Mapping for the smoker and sex columns\n",
    "df['smoker'] = df['smoker'].map({\"yes\":1, \"no\":0})\n",
    "df['sex'] = df['sex'].map({\"male\":1, \"female\":0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing OneHotEncoder for coverting the categorical values for regions.\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "variables = ['region']\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")\n",
    "one_hot_encodded= encoder.fit_transform(df[variables]).astype(int)\n",
    "df= pd.concat([df, one_hot_encodded], axis=1).drop(columns=variables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking distributtions of the prices.\n",
    "sns.histplot(df['charges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will try to make the data closer to the Nominal Distrubutions now\n",
    "df_cleaned = df.query(\"charges < charges.quantile(0.92)\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking distributtions of the prices.\n",
    "sns.histplot(df_cleaned['charges'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Still it's not a good distriubtion it's rightly skewed need to find some alternative to make this as nominal distributions as possible.\n",
    "- First let's check with a model and if needed we can find some alternatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've currently 1231 rows of datas\n",
    "df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase figure size\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# let's see the correlation matrix\n",
    "# based on this, smoker is the most important support variable for charges.\n",
    "correlations = df_cleaned.corr(numeric_only=True)\n",
    "sns.heatmap(correlations, annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_cleaned['smoker'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we do split between X and y.\n",
    "\n",
    "X = df_cleaned.drop(\"charges\", axis=1)\n",
    "\n",
    "# our target variable is y\n",
    "y = df_cleaned[\"charges\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the Most Important Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 1: Fisher's score\n",
    "# pip install skfeature-chappers\n",
    "from skfeature.function.similarity_based import fisher_score\n",
    "\n",
    "# get the fisher's score rankings \n",
    "ranks = fisher_score.fisher_score(X.values, y.values)\n",
    "\n",
    "# create a pandas DataFrame for easier interpretation\n",
    "feat_importances = pd.Series(ranks, X.columns)\n",
    "feat_importances.plot(kind='barh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
